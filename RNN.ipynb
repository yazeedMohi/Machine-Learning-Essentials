{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "raw_rnn() got an unexpected keyword argument 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-ee8cfb316ee6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'float'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_chunks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m \u001b[0mtrain_neural_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-19-ee8cfb316ee6>\u001b[0m in \u001b[0;36mtrain_neural_network\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrain_neural_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecurrent_neural_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m     \u001b[0mcost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax_cross_entropy_with_logits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-ee8cfb316ee6>\u001b[0m in \u001b[0;36mrecurrent_neural_network\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mlstm_cell\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnn_cell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBasicLSTMCell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrnn_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_rnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlstm_cell\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: raw_rnn() got an unexpected keyword argument 'dtype'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from tensorflow.python.ops import rnn, rnn_cell\n",
    "\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\",one_hot = True)\n",
    "\n",
    "hm_epochs = 10\n",
    "n_classes = 10\n",
    "batch_size = 128\n",
    "chunk_size = 28\n",
    "n_chunks = 28\n",
    "rnn_size = 128\n",
    "\n",
    "\n",
    "x = tf.placeholder('float',[None, n_chunks,chunk_size])\n",
    "y = tf.placeholder('float')\n",
    "\n",
    "def recurrent_neural_network(x):\n",
    "    layer = {'weights':tf.Variable(tf.random_normal([rnn_size,n_classes])),\n",
    "         'biases':tf.Variable(tf.random_normal([n_classes]))}\n",
    "    \n",
    "    x = tf.transpose(x, [1,0,2])\n",
    "    x = tf.reshape(x, [-1, chunk_size])\n",
    "    x = tf.split(x,n_chunks)\n",
    "    \n",
    "    lstm_cell = rnn_cell.BasicLSTMCell(rnn_size)\n",
    "    outputs, states = rnn.dynamic_rnn(lstm_cell, x,dtype = tf.float32)\n",
    "    \n",
    "    \n",
    "    output = tf.matmul(outputs[-1],layer['weights']) + layer['biases']\n",
    "    return output\n",
    "\n",
    "def train_neural_network(x):\n",
    "    prediction = recurrent_neural_network(x)\n",
    "    cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(logits=prediction,labels = y))\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "    \n",
    "  \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.initialize_all_variables())\n",
    "        \n",
    "        for epoch in range(hm_epochs):\n",
    "            epoch_loss = 0\n",
    "            for _ in range(int(mnist.train.num_examples / batch_size)):\n",
    "                epoch_x,epoch_y = mnist.train.next_batch(batch_size)\n",
    "                epoch_x = epoch_x.reshape((batch_size,n_chunks,chunk_size))\n",
    "                _, c = sess.run([optimizer, cost], feed_dict = {x:epoch_x , y:epoch_y})\n",
    "                epoch_loss += c\n",
    "            print('Epoch', epoch+1,'completed out of',hm_epochs,'loss',epoch_loss)\n",
    "        \n",
    "        correct = tf.equal(tf.argmax(prediction,1), tf.argmax(y,1))\n",
    "        \n",
    "        accuracy = tf.reduce_mean(tf.cast(correct,'float'))\n",
    "        print('Accuracy',accuracy.eval({x:mnist.test.images.reshape((-1,n_chunks,chunk_size)),y:mnist.test.labels}))\n",
    "train_neural_network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module tensorflow.python.ops.rnn in tensorflow.python.ops:\n",
      "\n",
      "NAME\n",
      "    tensorflow.python.ops.rnn - RNN helpers for TensorFlow models.\n",
      "\n",
      "FUNCTIONS\n",
      "    bidirectional_dynamic_rnn(cell_fw, cell_bw, inputs, sequence_length=None, initial_state_fw=None, initial_state_bw=None, dtype=None, parallel_iterations=None, swap_memory=False, time_major=False, scope=None)\n",
      "        Creates a dynamic version of bidirectional recurrent neural network. (deprecated)\n",
      "        \n",
      "        Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "        \n",
      "        Takes input and builds independent forward and backward RNNs. The input_size\n",
      "        of forward and backward cell must match. The initial state for both directions\n",
      "        is zero by default (but can be set optionally) and no intermediate states are\n",
      "        ever returned -- the network is fully unrolled for the given (passed in)\n",
      "        length(s) of the sequence(s) or completely unrolled if length(s) is not\n",
      "        given.\n",
      "        \n",
      "        Args:\n",
      "          cell_fw: An instance of RNNCell, to be used for forward direction.\n",
      "          cell_bw: An instance of RNNCell, to be used for backward direction.\n",
      "          inputs: The RNN inputs.\n",
      "            If time_major == False (default), this must be a tensor of shape:\n",
      "              `[batch_size, max_time, ...]`, or a nested tuple of such elements.\n",
      "            If time_major == True, this must be a tensor of shape: `[max_time,\n",
      "              batch_size, ...]`, or a nested tuple of such elements.\n",
      "          sequence_length: (optional) An int32/int64 vector, size `[batch_size]`,\n",
      "            containing the actual lengths for each of the sequences in the batch. If\n",
      "            not provided, all batch entries are assumed to be full sequences; and time\n",
      "            reversal is applied from time `0` to `max_time` for each sequence.\n",
      "          initial_state_fw: (optional) An initial state for the forward RNN. This must\n",
      "            be a tensor of appropriate type and shape `[batch_size,\n",
      "            cell_fw.state_size]`. If `cell_fw.state_size` is a tuple, this should be a\n",
      "            tuple of tensors having shapes `[batch_size, s] for s in\n",
      "            cell_fw.state_size`.\n",
      "          initial_state_bw: (optional) Same as for `initial_state_fw`, but using the\n",
      "            corresponding properties of `cell_bw`.\n",
      "          dtype: (optional) The data type for the initial states and expected output.\n",
      "            Required if initial_states are not provided or RNN states have a\n",
      "            heterogeneous dtype.\n",
      "          parallel_iterations: (Default: 32).  The number of iterations to run in\n",
      "            parallel.  Those operations which do not have any temporal dependency and\n",
      "            can be run in parallel, will be.  This parameter trades off time for\n",
      "            space.  Values >> 1 use more memory but take less time, while smaller\n",
      "            values use less memory but computations take longer.\n",
      "          swap_memory: Transparently swap the tensors produced in forward inference\n",
      "            but needed for back prop from GPU to CPU.  This allows training RNNs which\n",
      "            would typically not fit on a single GPU, with very minimal (or no)\n",
      "            performance penalty.\n",
      "          time_major: The shape format of the `inputs` and `outputs` Tensors. If true,\n",
      "            these `Tensors` must be shaped `[max_time, batch_size, depth]`. If false,\n",
      "            these `Tensors` must be shaped `[batch_size, max_time, depth]`. Using\n",
      "            `time_major = True` is a bit more efficient because it avoids transposes\n",
      "            at the beginning and end of the RNN calculation.  However, most TensorFlow\n",
      "            data is batch-major, so by default this function accepts input and emits\n",
      "            output in batch-major form.\n",
      "          scope: VariableScope for the created subgraph; defaults to\n",
      "            \"bidirectional_rnn\"\n",
      "        \n",
      "        Returns:\n",
      "          A tuple (outputs, output_states) where:\n",
      "            outputs: A tuple (output_fw, output_bw) containing the forward and\n",
      "              the backward rnn output `Tensor`.\n",
      "              If time_major == False (default),\n",
      "                output_fw will be a `Tensor` shaped:\n",
      "                `[batch_size, max_time, cell_fw.output_size]`\n",
      "                and output_bw will be a `Tensor` shaped:\n",
      "                `[batch_size, max_time, cell_bw.output_size]`.\n",
      "              If time_major == True,\n",
      "                output_fw will be a `Tensor` shaped:\n",
      "                `[max_time, batch_size, cell_fw.output_size]`\n",
      "                and output_bw will be a `Tensor` shaped:\n",
      "                `[max_time, batch_size, cell_bw.output_size]`.\n",
      "              It returns a tuple instead of a single concatenated `Tensor`, unlike\n",
      "              in the `bidirectional_rnn`. If the concatenated one is preferred,\n",
      "              the forward and backward outputs can be concatenated as\n",
      "              `tf.concat(outputs, 2)`.\n",
      "            output_states: A tuple (output_state_fw, output_state_bw) containing\n",
      "              the forward and the backward final states of bidirectional rnn.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `cell_fw` or `cell_bw` is not an instance of `RNNCell`.\n",
      "    \n",
      "    dynamic_rnn(cell, inputs, sequence_length=None, initial_state=None, dtype=None, parallel_iterations=None, swap_memory=False, time_major=False, scope=None)\n",
      "        Creates a recurrent neural network specified by RNNCell `cell`. (deprecated)\n",
      "        \n",
      "        Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "        \n",
      "        Performs fully dynamic unrolling of `inputs`.\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        ```python\n",
      "        # create a BasicRNNCell\n",
      "        rnn_cell = tf.compat.v1.nn.rnn_cell.BasicRNNCell(hidden_size)\n",
      "        \n",
      "        # 'outputs' is a tensor of shape [batch_size, max_time, cell_state_size]\n",
      "        \n",
      "        # defining initial state\n",
      "        initial_state = rnn_cell.zero_state(batch_size, dtype=tf.float32)\n",
      "        \n",
      "        # 'state' is a tensor of shape [batch_size, cell_state_size]\n",
      "        outputs, state = tf.compat.v1.nn.dynamic_rnn(rnn_cell, input_data,\n",
      "                                           initial_state=initial_state,\n",
      "                                           dtype=tf.float32)\n",
      "        ```\n",
      "        \n",
      "        ```python\n",
      "        # create 2 LSTMCells\n",
      "        rnn_layers = [tf.compat.v1.nn.rnn_cell.LSTMCell(size) for size in [128, 256]]\n",
      "        \n",
      "        # create a RNN cell composed sequentially of a number of RNNCells\n",
      "        multi_rnn_cell = tf.compat.v1.nn.rnn_cell.MultiRNNCell(rnn_layers)\n",
      "        \n",
      "        # 'outputs' is a tensor of shape [batch_size, max_time, 256]\n",
      "        # 'state' is a N-tuple where N is the number of LSTMCells containing a\n",
      "        # tf.nn.rnn_cell.LSTMStateTuple for each cell\n",
      "        outputs, state = tf.compat.v1.nn.dynamic_rnn(cell=multi_rnn_cell,\n",
      "                                           inputs=data,\n",
      "                                           dtype=tf.float32)\n",
      "        ```\n",
      "        \n",
      "        \n",
      "        Args:\n",
      "          cell: An instance of RNNCell.\n",
      "          inputs: The RNN inputs.\n",
      "            If `time_major == False` (default), this must be a `Tensor` of shape:\n",
      "              `[batch_size, max_time, ...]`, or a nested tuple of such elements.\n",
      "            If `time_major == True`, this must be a `Tensor` of shape: `[max_time,\n",
      "              batch_size, ...]`, or a nested tuple of such elements. This may also be\n",
      "              a (possibly nested) tuple of Tensors satisfying this property.  The\n",
      "              first two dimensions must match across all the inputs, but otherwise the\n",
      "              ranks and other shape components may differ. In this case, input to\n",
      "              `cell` at each time-step will replicate the structure of these tuples,\n",
      "              except for the time dimension (from which the time is taken). The input\n",
      "              to `cell` at each time step will be a `Tensor` or (possibly nested)\n",
      "              tuple of Tensors each with dimensions `[batch_size, ...]`.\n",
      "          sequence_length: (optional) An int32/int64 vector sized `[batch_size]`. Used\n",
      "            to copy-through state and zero-out outputs when past a batch element's\n",
      "            sequence length.  This parameter enables users to extract the last valid\n",
      "            state and properly padded outputs, so it is provided for correctness.\n",
      "          initial_state: (optional) An initial state for the RNN. If `cell.state_size`\n",
      "            is an integer, this must be a `Tensor` of appropriate type and shape\n",
      "            `[batch_size, cell.state_size]`. If `cell.state_size` is a tuple, this\n",
      "            should be a tuple of tensors having shapes `[batch_size, s] for s in\n",
      "            cell.state_size`.\n",
      "          dtype: (optional) The data type for the initial state and expected output.\n",
      "            Required if initial_state is not provided or RNN state has a heterogeneous\n",
      "            dtype.\n",
      "          parallel_iterations: (Default: 32).  The number of iterations to run in\n",
      "            parallel.  Those operations which do not have any temporal dependency and\n",
      "            can be run in parallel, will be.  This parameter trades off time for\n",
      "            space.  Values >> 1 use more memory but take less time, while smaller\n",
      "            values use less memory but computations take longer.\n",
      "          swap_memory: Transparently swap the tensors produced in forward inference\n",
      "            but needed for back prop from GPU to CPU.  This allows training RNNs which\n",
      "            would typically not fit on a single GPU, with very minimal (or no)\n",
      "            performance penalty.\n",
      "          time_major: The shape format of the `inputs` and `outputs` Tensors. If true,\n",
      "            these `Tensors` must be shaped `[max_time, batch_size, depth]`. If false,\n",
      "            these `Tensors` must be shaped `[batch_size, max_time, depth]`. Using\n",
      "            `time_major = True` is a bit more efficient because it avoids transposes\n",
      "            at the beginning and end of the RNN calculation.  However, most TensorFlow\n",
      "            data is batch-major, so by default this function accepts input and emits\n",
      "            output in batch-major form.\n",
      "          scope: VariableScope for the created subgraph; defaults to \"rnn\".\n",
      "        \n",
      "        Returns:\n",
      "          A pair (outputs, state) where:\n",
      "        \n",
      "          outputs: The RNN output `Tensor`.\n",
      "        \n",
      "            If time_major == False (default), this will be a `Tensor` shaped:\n",
      "              `[batch_size, max_time, cell.output_size]`.\n",
      "        \n",
      "            If time_major == True, this will be a `Tensor` shaped:\n",
      "              `[max_time, batch_size, cell.output_size]`.\n",
      "        \n",
      "            Note, if `cell.output_size` is a (possibly nested) tuple of integers\n",
      "            or `TensorShape` objects, then `outputs` will be a tuple having the\n",
      "            same structure as `cell.output_size`, containing Tensors having shapes\n",
      "            corresponding to the shape data in `cell.output_size`.\n",
      "        \n",
      "          state: The final state.  If `cell.state_size` is an int, this\n",
      "            will be shaped `[batch_size, cell.state_size]`.  If it is a\n",
      "            `TensorShape`, this will be shaped `[batch_size] + cell.state_size`.\n",
      "            If it is a (possibly nested) tuple of ints or `TensorShape`, this will\n",
      "            be a tuple having the corresponding shapes. If cells are `LSTMCells`\n",
      "            `state` will be a tuple containing a `LSTMStateTuple` for each cell.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `cell` is not an instance of RNNCell.\n",
      "          ValueError: If inputs is None or an empty list.\n",
      "    \n",
      "    raw_rnn(cell, loop_fn, parallel_iterations=None, swap_memory=False, scope=None)\n",
      "        Creates an `RNN` specified by RNNCell `cell` and loop function `loop_fn`.\n",
      "        \n",
      "        **NOTE: This method is still in testing, and the API may change.**\n",
      "        \n",
      "        This function is a more primitive version of `dynamic_rnn` that provides\n",
      "        more direct access to the inputs each iteration.  It also provides more\n",
      "        control over when to start and finish reading the sequence, and\n",
      "        what to emit for the output.\n",
      "        \n",
      "        For example, it can be used to implement the dynamic decoder of a seq2seq\n",
      "        model.\n",
      "        \n",
      "        Instead of working with `Tensor` objects, most operations work with\n",
      "        `TensorArray` objects directly.\n",
      "        \n",
      "        The operation of `raw_rnn`, in pseudo-code, is basically the following:\n",
      "        \n",
      "        ```python\n",
      "        time = tf.constant(0, dtype=tf.int32)\n",
      "        (finished, next_input, initial_state, emit_structure, loop_state) = loop_fn(\n",
      "            time=time, cell_output=None, cell_state=None, loop_state=None)\n",
      "        emit_ta = TensorArray(dynamic_size=True, dtype=initial_state.dtype)\n",
      "        state = initial_state\n",
      "        while not all(finished):\n",
      "          (output, cell_state) = cell(next_input, state)\n",
      "          (next_finished, next_input, next_state, emit, loop_state) = loop_fn(\n",
      "              time=time + 1, cell_output=output, cell_state=cell_state,\n",
      "              loop_state=loop_state)\n",
      "          # Emit zeros and copy forward state for minibatch entries that are finished.\n",
      "          state = tf.where(finished, state, next_state)\n",
      "          emit = tf.where(finished, tf.zeros_like(emit_structure), emit)\n",
      "          emit_ta = emit_ta.write(time, emit)\n",
      "          # If any new minibatch entries are marked as finished, mark these.\n",
      "          finished = tf.logical_or(finished, next_finished)\n",
      "          time += 1\n",
      "        return (emit_ta, state, loop_state)\n",
      "        ```\n",
      "        \n",
      "        with the additional properties that output and state may be (possibly nested)\n",
      "        tuples, as determined by `cell.output_size` and `cell.state_size`, and\n",
      "        as a result the final `state` and `emit_ta` may themselves be tuples.\n",
      "        \n",
      "        A simple implementation of `dynamic_rnn` via `raw_rnn` looks like this:\n",
      "        \n",
      "        ```python\n",
      "        inputs = tf.compat.v1.placeholder(shape=(max_time, batch_size, input_depth),\n",
      "                                dtype=tf.float32)\n",
      "        sequence_length = tf.compat.v1.placeholder(shape=(batch_size,),\n",
      "        dtype=tf.int32)\n",
      "        inputs_ta = tf.TensorArray(dtype=tf.float32, size=max_time)\n",
      "        inputs_ta = inputs_ta.unstack(inputs)\n",
      "        \n",
      "        cell = tf.compat.v1.nn.rnn_cell.LSTMCell(num_units)\n",
      "        \n",
      "        def loop_fn(time, cell_output, cell_state, loop_state):\n",
      "          emit_output = cell_output  # == None for time == 0\n",
      "          if cell_output is None:  # time == 0\n",
      "            next_cell_state = cell.zero_state(batch_size, tf.float32)\n",
      "          else:\n",
      "            next_cell_state = cell_state\n",
      "          elements_finished = (time >= sequence_length)\n",
      "          finished = tf.reduce_all(elements_finished)\n",
      "          next_input = tf.cond(\n",
      "              finished,\n",
      "              lambda: tf.zeros([batch_size, input_depth], dtype=tf.float32),\n",
      "              lambda: inputs_ta.read(time))\n",
      "          next_loop_state = None\n",
      "          return (elements_finished, next_input, next_cell_state,\n",
      "                  emit_output, next_loop_state)\n",
      "        \n",
      "        outputs_ta, final_state, _ = raw_rnn(cell, loop_fn)\n",
      "        outputs = outputs_ta.stack()\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          cell: An instance of RNNCell.\n",
      "          loop_fn: A callable that takes inputs `(time, cell_output, cell_state,\n",
      "            loop_state)` and returns the tuple `(finished, next_input,\n",
      "            next_cell_state, emit_output, next_loop_state)`. Here `time` is an int32\n",
      "            scalar `Tensor`, `cell_output` is a `Tensor` or (possibly nested) tuple of\n",
      "            tensors as determined by `cell.output_size`, and `cell_state` is a\n",
      "            `Tensor` or (possibly nested) tuple of tensors, as determined by the\n",
      "            `loop_fn` on its first call (and should match `cell.state_size`).\n",
      "            The outputs are: `finished`, a boolean `Tensor` of\n",
      "            shape `[batch_size]`, `next_input`: the next input to feed to `cell`,\n",
      "            `next_cell_state`: the next state to feed to `cell`,\n",
      "            and `emit_output`: the output to store for this iteration.  Note that\n",
      "              `emit_output` should be a `Tensor` or (possibly nested) tuple of tensors\n",
      "              which is aggregated in the `emit_ta` inside the `while_loop`. For the\n",
      "              first call to `loop_fn`, the `emit_output` corresponds to the\n",
      "              `emit_structure` which is then used to determine the size of the\n",
      "              `zero_tensor` for the `emit_ta` (defaults to `cell.output_size`). For\n",
      "              the subsequent calls to the `loop_fn`, the `emit_output` corresponds to\n",
      "              the actual output tensor that is to be aggregated in the `emit_ta`. The\n",
      "              parameter `cell_state` and output `next_cell_state` may be either a\n",
      "              single or (possibly nested) tuple of tensors.  The parameter\n",
      "              `loop_state` and output `next_loop_state` may be either a single or\n",
      "              (possibly nested) tuple of `Tensor` and `TensorArray` objects.  This\n",
      "              last parameter may be ignored by `loop_fn` and the return value may be\n",
      "              `None`.  If it is not `None`, then the `loop_state` will be propagated\n",
      "              through the RNN loop, for use purely by `loop_fn` to keep track of its\n",
      "              own state. The `next_loop_state` parameter returned may be `None`.  The\n",
      "              first call to `loop_fn` will be `time = 0`, `cell_output = None`,\n",
      "            `cell_state = None`, and `loop_state = None`.  For this call: The\n",
      "              `next_cell_state` value should be the value with which to initialize the\n",
      "              cell's state.  It may be a final state from a previous RNN or it may be\n",
      "              the output of `cell.zero_state()`.  It should be a (possibly nested)\n",
      "              tuple structure of tensors. If `cell.state_size` is an integer, this\n",
      "              must be a `Tensor` of appropriate type and shape `[batch_size,\n",
      "              cell.state_size]`. If `cell.state_size` is a `TensorShape`, this must be\n",
      "              a `Tensor` of appropriate type and shape `[batch_size] +\n",
      "              cell.state_size`. If `cell.state_size` is a (possibly nested) tuple of\n",
      "              ints or `TensorShape`, this will be a tuple having the corresponding\n",
      "              shapes. The `emit_output` value may be either `None` or a (possibly\n",
      "              nested) tuple structure of tensors, e.g., `(tf.zeros(shape_0,\n",
      "              dtype=dtype_0), tf.zeros(shape_1, dtype=dtype_1))`. If this first\n",
      "              `emit_output` return value is `None`, then the `emit_ta` result of\n",
      "              `raw_rnn` will have the same structure and dtypes as `cell.output_size`.\n",
      "              Otherwise `emit_ta` will have the same structure, shapes (prepended with\n",
      "              a `batch_size` dimension), and dtypes as `emit_output`.  The actual\n",
      "              values returned for `emit_output` at this initializing call are ignored.\n",
      "              Note, this emit structure must be consistent across all time steps.\n",
      "          parallel_iterations: (Default: 32).  The number of iterations to run in\n",
      "            parallel.  Those operations which do not have any temporal dependency and\n",
      "            can be run in parallel, will be.  This parameter trades off time for\n",
      "            space.  Values >> 1 use more memory but take less time, while smaller\n",
      "            values use less memory but computations take longer.\n",
      "          swap_memory: Transparently swap the tensors produced in forward inference\n",
      "            but needed for back prop from GPU to CPU.  This allows training RNNs which\n",
      "            would typically not fit on a single GPU, with very minimal (or no)\n",
      "            performance penalty.\n",
      "          scope: VariableScope for the created subgraph; defaults to \"rnn\".\n",
      "        \n",
      "        Returns:\n",
      "          A tuple `(emit_ta, final_state, final_loop_state)` where:\n",
      "        \n",
      "          `emit_ta`: The RNN output `TensorArray`.\n",
      "             If `loop_fn` returns a (possibly nested) set of Tensors for\n",
      "             `emit_output` during initialization, (inputs `time = 0`,\n",
      "             `cell_output = None`, and `loop_state = None`), then `emit_ta` will\n",
      "             have the same structure, dtypes, and shapes as `emit_output` instead.\n",
      "             If `loop_fn` returns `emit_output = None` during this call,\n",
      "             the structure of `cell.output_size` is used:\n",
      "             If `cell.output_size` is a (possibly nested) tuple of integers\n",
      "             or `TensorShape` objects, then `emit_ta` will be a tuple having the\n",
      "             same structure as `cell.output_size`, containing TensorArrays whose\n",
      "             elements' shapes correspond to the shape data in `cell.output_size`.\n",
      "        \n",
      "          `final_state`: The final cell state.  If `cell.state_size` is an int, this\n",
      "            will be shaped `[batch_size, cell.state_size]`.  If it is a\n",
      "            `TensorShape`, this will be shaped `[batch_size] + cell.state_size`.\n",
      "            If it is a (possibly nested) tuple of ints or `TensorShape`, this will\n",
      "            be a tuple having the corresponding shapes.\n",
      "        \n",
      "          `final_loop_state`: The final loop state as returned by `loop_fn`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `cell` is not an instance of RNNCell, or `loop_fn` is not\n",
      "            a `callable`.\n",
      "    \n",
      "    static_bidirectional_rnn(cell_fw, cell_bw, inputs, initial_state_fw=None, initial_state_bw=None, dtype=None, sequence_length=None, scope=None)\n",
      "        Creates a bidirectional recurrent neural network. (deprecated)\n",
      "        \n",
      "        Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Please use `keras.layers.Bidirectional(keras.layers.RNN(cell, unroll=True))`, which is equivalent to this API\n",
      "        \n",
      "        Similar to the unidirectional case above (rnn) but takes input and builds\n",
      "        independent forward and backward RNNs with the final forward and backward\n",
      "        outputs depth-concatenated, such that the output will have the format\n",
      "        [time][batch][cell_fw.output_size + cell_bw.output_size]. The input_size of\n",
      "        forward and backward cell must match. The initial state for both directions\n",
      "        is zero by default (but can be set optionally) and no intermediate states are\n",
      "        ever returned -- the network is fully unrolled for the given (passed in)\n",
      "        length(s) of the sequence(s) or completely unrolled if length(s) is not given.\n",
      "        \n",
      "        Args:\n",
      "          cell_fw: An instance of RNNCell, to be used for forward direction.\n",
      "          cell_bw: An instance of RNNCell, to be used for backward direction.\n",
      "          inputs: A length T list of inputs, each a tensor of shape [batch_size,\n",
      "            input_size], or a nested tuple of such elements.\n",
      "          initial_state_fw: (optional) An initial state for the forward RNN. This must\n",
      "            be a tensor of appropriate type and shape `[batch_size,\n",
      "            cell_fw.state_size]`. If `cell_fw.state_size` is a tuple, this should be a\n",
      "            tuple of tensors having shapes `[batch_size, s] for s in\n",
      "            cell_fw.state_size`.\n",
      "          initial_state_bw: (optional) Same as for `initial_state_fw`, but using the\n",
      "            corresponding properties of `cell_bw`.\n",
      "          dtype: (optional) The data type for the initial state.  Required if either\n",
      "            of the initial states are not provided.\n",
      "          sequence_length: (optional) An int32/int64 vector, size `[batch_size]`,\n",
      "            containing the actual lengths for each of the sequences.\n",
      "          scope: VariableScope for the created subgraph; defaults to\n",
      "            \"bidirectional_rnn\"\n",
      "        \n",
      "        Returns:\n",
      "          A tuple (outputs, output_state_fw, output_state_bw) where:\n",
      "            outputs is a length `T` list of outputs (one for each input), which\n",
      "              are depth-concatenated forward and backward outputs.\n",
      "            output_state_fw is the final state of the forward rnn.\n",
      "            output_state_bw is the final state of the backward rnn.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `cell_fw` or `cell_bw` is not an instance of `RNNCell`.\n",
      "          ValueError: If inputs is None or an empty list.\n",
      "    \n",
      "    static_rnn(cell, inputs, initial_state=None, dtype=None, sequence_length=None, scope=None)\n",
      "        Creates a recurrent neural network specified by RNNCell `cell`. (deprecated)\n",
      "        \n",
      "        Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
      "        \n",
      "        The simplest form of RNN network generated is:\n",
      "        \n",
      "        ```python\n",
      "          state = cell.zero_state(...)\n",
      "          outputs = []\n",
      "          for input_ in inputs:\n",
      "            output, state = cell(input_, state)\n",
      "            outputs.append(output)\n",
      "          return (outputs, state)\n",
      "        ```\n",
      "        However, a few other options are available:\n",
      "        \n",
      "        An initial state can be provided.\n",
      "        If the sequence_length vector is provided, dynamic calculation is performed.\n",
      "        This method of calculation does not compute the RNN steps past the maximum\n",
      "        sequence length of the minibatch (thus saving computational time),\n",
      "        and properly propagates the state at an example's sequence length\n",
      "        to the final state output.\n",
      "        \n",
      "        The dynamic calculation performed is, at time `t` for batch row `b`,\n",
      "        \n",
      "        ```python\n",
      "          (output, state)(b, t) =\n",
      "            (t >= sequence_length(b))\n",
      "              ? (zeros(cell.output_size), states(b, sequence_length(b) - 1))\n",
      "              : cell(input(b, t), state(b, t - 1))\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          cell: An instance of RNNCell.\n",
      "          inputs: A length T list of inputs, each a `Tensor` of shape `[batch_size,\n",
      "            input_size]`, or a nested tuple of such elements.\n",
      "          initial_state: (optional) An initial state for the RNN. If `cell.state_size`\n",
      "            is an integer, this must be a `Tensor` of appropriate type and shape\n",
      "            `[batch_size, cell.state_size]`. If `cell.state_size` is a tuple, this\n",
      "            should be a tuple of tensors having shapes `[batch_size, s] for s in\n",
      "            cell.state_size`.\n",
      "          dtype: (optional) The data type for the initial state and expected output.\n",
      "            Required if initial_state is not provided or RNN state has a heterogeneous\n",
      "            dtype.\n",
      "          sequence_length: Specifies the length of each sequence in inputs. An int32\n",
      "            or int64 vector (tensor) size `[batch_size]`, values in `[0, T)`.\n",
      "          scope: VariableScope for the created subgraph; defaults to \"rnn\".\n",
      "        \n",
      "        Returns:\n",
      "          A pair (outputs, state) where:\n",
      "        \n",
      "          - outputs is a length T list of outputs (one for each input), or a nested\n",
      "            tuple of such elements.\n",
      "          - state is the final state\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `cell` is not an instance of RNNCell.\n",
      "          ValueError: If `inputs` is `None` or an empty list, or if the input depth\n",
      "            (column size) cannot be inferred from inputs via shape inference.\n",
      "    \n",
      "    static_state_saving_rnn(cell, inputs, state_saver, state_name, sequence_length=None, scope=None)\n",
      "        RNN that accepts a state saver for time-truncated RNN calculation. (deprecated)\n",
      "        \n",
      "        Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Please use `keras.layers.RNN(cell, stateful=True)`, which is equivalent to this API\n",
      "        \n",
      "        Args:\n",
      "          cell: An instance of `RNNCell`.\n",
      "          inputs: A length T list of inputs, each a `Tensor` of shape `[batch_size,\n",
      "            input_size]`.\n",
      "          state_saver: A state saver object with methods `state` and `save_state`.\n",
      "          state_name: Python string or tuple of strings.  The name to use with the\n",
      "            state_saver. If the cell returns tuples of states (i.e., `cell.state_size`\n",
      "            is a tuple) then `state_name` should be a tuple of strings having the same\n",
      "            length as `cell.state_size`.  Otherwise it should be a single string.\n",
      "          sequence_length: (optional) An int32/int64 vector size [batch_size]. See the\n",
      "            documentation for rnn() for more details about sequence_length.\n",
      "          scope: VariableScope for the created subgraph; defaults to \"rnn\".\n",
      "        \n",
      "        Returns:\n",
      "          A pair (outputs, state) where:\n",
      "            outputs is a length T list of outputs (one for each input)\n",
      "            states is the final state\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `cell` is not an instance of RNNCell.\n",
      "          ValueError: If `inputs` is `None` or an empty list, or if the arity and\n",
      "           type of `state_name` does not match that of `cell.state_size`.\n",
      "\n",
      "DATA\n",
      "    absolute_import = _Feature((2, 5, 0, 'alpha', 1), (3, 0, 0, 'alpha', 0...\n",
      "    division = _Feature((2, 2, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0), 8192...\n",
      "    print_function = _Feature((2, 6, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0)...\n",
      "    tf_export = functools.partial(<class 'tensorflow.python.util.tf_export...\n",
      "\n",
      "FILE\n",
      "    c:\\users\\yazeed\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
